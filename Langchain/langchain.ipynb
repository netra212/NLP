{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a0f7945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "585acbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_google_genai in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (2.1.5)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_google_genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_google_genai) (0.6.18)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.62 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_google_genai) (0.3.65)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_google_genai) (2.11.7)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (6.31.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.73.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5325023d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_openai) (0.3.65)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_openai) (1.88.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (2.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c8e9fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_anthropic in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (0.3.15)\n",
      "Requirement already satisfied: anthropic<1,>=0.52.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_anthropic) (0.54.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.63 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_anthropic) (0.3.65)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_anthropic) (2.11.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from anthropic<1,>=0.52.0->langchain_anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from anthropic<1,>=0.52.0->langchain_anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from anthropic<1,>=0.52.0->langchain_anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from anthropic<1,>=0.52.0->langchain_anthropic) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from anthropic<1,>=0.52.0->langchain_anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from anthropic<1,>=0.52.0->langchain_anthropic) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.52.0->langchain_anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.52.0->langchain_anthropic) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.52.0->langchain_anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1,>=0.52.0->langchain_anthropic) (0.16.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.63->langchain_anthropic) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbb3f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_huggingface in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_huggingface) (0.3.65)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_huggingface) (0.21.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain_huggingface) (0.33.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (2.5.0)\n",
      "Requirement already satisfied: filelock in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (2025.3.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (1.1.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_huggingface) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c184a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad32be5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='meta-llama/Llama-2-7b-hf0', stop_sequences=[], server_kwargs={}, model_kwargs={}, model='meta-llama/Llama-2-7b-hf0', client=<InferenceClient(model='meta-llama/Llama-2-7b-hf0', timeout=120)>, async_client=<InferenceClient(model='meta-llama/Llama-2-7b-hf0', timeout=120)>, task='text-generation')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the model from the hugging face via huggingfaceendpoint. \n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id = \"meta-llama/Llama-2-7b-hf0\",\n",
    "    task = \"text-generation\"\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da9131",
   "metadata": {},
   "outputs": [
    {
     "ename": "RepositoryNotFoundError",
     "evalue": "404 Client Error. (Request ID: Root=1-6855ee4d-0fdb25a87d33f44573dc45f7;789b4ab9-1ca3-4c88-8b34-201a1aae5509)\n\nRepository Not Found for url: https://huggingface.co/api/models/meta-llama/Llama-2-7b-hf0?expand=inferenceProviderMapping.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://huggingface.co/api/models/meta-llama/Llama-2-7b-hf0?expand=inferenceProviderMapping",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m model = ChatHuggingFace(\n\u001b[32m      2\u001b[39m     llm = llm\n\u001b[32m      3\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the capital city of the Nepal ?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_huggingface/chat_models/huggingface.py:574\u001b[39m, in \u001b[36mChatHuggingFace._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m     message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    568\u001b[39m     params = {\n\u001b[32m    569\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    570\u001b[39m         **params,\n\u001b[32m    571\u001b[39m         **({\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m    572\u001b[39m         **kwargs,\n\u001b[32m    573\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(answer)\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/huggingface_hub/inference/_client.py:887\u001b[39m, in \u001b[36mInferenceClient.chat_completion\u001b[39m\u001b[34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[39m\n\u001b[32m    884\u001b[39m payload_model = model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model\n\u001b[32m    886\u001b[39m \u001b[38;5;66;03m# Get the provider helper\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m provider_helper = \u001b[43mget_provider_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversational\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id_or_url\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_id_or_url\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_id_or_url\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttp://\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpayload_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[38;5;66;03m# Prepare the payload\u001b[39;00m\n\u001b[32m    896\u001b[39m parameters = {\n\u001b[32m    897\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: payload_model,\n\u001b[32m    898\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   (...)\u001b[39m\u001b[32m    915\u001b[39m     **(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    916\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/huggingface_hub/inference/_providers/__init__.py:190\u001b[39m, in \u001b[36mget_provider_helper\u001b[39m\u001b[34m(provider, task, model)\u001b[39m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    189\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSpecifying a model is required when provider is \u001b[39m\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     provider_mapping = \u001b[43m_fetch_inference_provider_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m     provider = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(provider_mapping)).provider\n\u001b[32m    193\u001b[39m provider_tasks = PROVIDERS.get(provider)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/huggingface_hub/inference/_providers/_common.py:257\u001b[39m, in \u001b[36m_fetch_inference_provider_mapping\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03mFetch provider mappings for a model from the Hub.\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhf_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HfApi\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m info = \u001b[43mHfApi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minferenceProviderMapping\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m provider_mapping = info.inference_provider_mapping\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m provider_mapping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/huggingface_hub/hf_api.py:2629\u001b[39m, in \u001b[36mHfApi.model_info\u001b[39m\u001b[34m(self, repo_id, revision, timeout, securityStatus, files_metadata, expand, token)\u001b[39m\n\u001b[32m   2627\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mexpand\u001b[39m\u001b[33m\"\u001b[39m] = expand\n\u001b[32m   2628\u001b[39m r = get_session().get(path, headers=headers, timeout=timeout, params=params)\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2630\u001b[39m data = r.json()\n\u001b[32m   2631\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(**data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:459\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_code == \u001b[33m\"\u001b[39m\u001b[33mRepoNotFound\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    439\u001b[39m     response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m    440\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m error_message != \u001b[33m\"\u001b[39m\u001b[33mInvalid credentials in Authorization header\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[32m    449\u001b[39m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[32m    450\u001b[39m     message = (\n\u001b[32m    451\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m400\u001b[39m:\n\u001b[32m    462\u001b[39m     message = (\n\u001b[32m    463\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m endpoint:\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBad request:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    464\u001b[39m     )\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m: 404 Client Error. (Request ID: Root=1-6855ee4d-0fdb25a87d33f44573dc45f7;789b4ab9-1ca3-4c88-8b34-201a1aae5509)\n\nRepository Not Found for url: https://huggingface.co/api/models/meta-llama/Llama-2-7b-hf0?expand=inferenceProviderMapping.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication"
     ]
    }
   ],
   "source": [
    "model = ChatHuggingFace(\n",
    "    llm = llm\n",
    ")\n",
    "\n",
    "model.invoke(\"What is the capital city of the Nepal ?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51dd0bc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Loading another model, this is just reading the model. \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m gemini_model = \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-1.5-pro\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m gemini_model.invoke(\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwhat is the capital city of the nepal ?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m ).content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1108\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1101\u001b[39m         suggestion = (\n\u001b[32m   1102\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Did you mean: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestions[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suggestions \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         )\n\u001b[32m   1104\u001b[39m         logger.warning(\n\u001b[32m   1105\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1106\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprovided to ChatGoogleGenerativeAI.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1107\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1108\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_core/load/serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1169\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1167\u001b[39m         google_api_key = \u001b[38;5;28mself\u001b[39m.google_api_key\n\u001b[32m   1168\u001b[39m transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28mself\u001b[39m.transport\n\u001b[32m-> \u001b[39m\u001b[32m1169\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mgenaix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_generative_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28mself\u001b[39m.async_client_running = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_google_genai/_genai_extension.py:276\u001b[39m, in \u001b[36mbuild_generative_service\u001b[39m\u001b[34m(credentials, api_key, client_options, client_info, transport)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_generative_service\u001b[39m(\n\u001b[32m    263\u001b[39m     credentials: Optional[credentials.Credentials] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    264\u001b[39m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m     transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    268\u001b[39m ) -> v1betaGenerativeServiceClient:\n\u001b[32m    269\u001b[39m     config = _prepare_config(\n\u001b[32m    270\u001b[39m         credentials=credentials,\n\u001b[32m    271\u001b[39m         api_key=api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m         client_info=client_info,\n\u001b[32m    275\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1betaGenerativeServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:697\u001b[39m, in \u001b[36mGenerativeServiceClient.__init__\u001b[39m\u001b[34m(self, credentials, transport, client_options, client_info)\u001b[39m\n\u001b[32m    688\u001b[39m     transport_init: Union[\n\u001b[32m    689\u001b[39m         Type[GenerativeServiceTransport],\n\u001b[32m    690\u001b[39m         Callable[..., GenerativeServiceTransport],\n\u001b[32m   (...)\u001b[39m\u001b[32m    694\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[..., GenerativeServiceTransport], transport)\n\u001b[32m    695\u001b[39m     )\n\u001b[32m    696\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m697\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport = \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33masync\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._transport):\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER.isEnabledFor(\n\u001b[32m    711\u001b[39m         std_logging.DEBUG\n\u001b[32m    712\u001b[39m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:234\u001b[39m, in \u001b[36mGenerativeServiceGrpcTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[39m\n\u001b[32m    229\u001b[39m             \u001b[38;5;28mself\u001b[39m._ssl_channel_credentials = grpc.ssl_channel_credentials(\n\u001b[32m    230\u001b[39m                 certificate_chain=cert, private_key=key\n\u001b[32m    231\u001b[39m             )\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grpc_channel:\n\u001b[32m    246\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[32m    247\u001b[39m     channel_init = channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).create_channel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py:100\u001b[39m, in \u001b[36mGenerativeServiceTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m     credentials, _ = google.auth.load_credentials_from_file(\n\u001b[32m     97\u001b[39m         credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n\u001b[32m     98\u001b[39m     )\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ignore_credentials:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     credentials, _ = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[33m\"\u001b[39m\u001b[33mwith_gdch_audience\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/google/auth/_default.py:685\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    677\u001b[39m             _LOGGER.warning(\n\u001b[32m    678\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mNo project ID could be determined. Consider running \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    679\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    680\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33menvironment variable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    681\u001b[39m                 environment_vars.PROJECT,\n\u001b[32m    682\u001b[39m             )\n\u001b[32m    683\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "# Loading another model, this is just reading the model. \n",
    "gemini_model = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-1.5-pro\"\n",
    ")\n",
    "\n",
    "gemini_model.invoke(\n",
    "    \"what is the capital city of the nepal ?\"\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f36671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading another model grok. \n",
    "grok_llm = ChatGroq(\n",
    "    model = \"deepseek-r1-distill-llama-70b\"\n",
    ")\n",
    "\n",
    "grok_llm.invoke(\n",
    "    \"what is the capital city of Nepal ?\"\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d815f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading another model. \n",
    "openai_model = ChatOpenAI(\n",
    "    model = \"gpt-4\"\n",
    ")\n",
    "\n",
    "openai_model.invoke(\n",
    "    \"What is the capital city of the Nepal ?\"\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796edfe",
   "metadata": {},
   "source": [
    "### **Embedding Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5876d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[32m      3\u001b[39m openai_embedding = OpenAIEmbeddings(\n\u001b[32m      4\u001b[39m     model = \u001b[33m\"\u001b[39m\u001b[33mtext-embedding-3-large\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m result  = \u001b[43mopenai_embedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNepal is a growing country\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mlen\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_openai/embeddings/base.py:638\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_query\u001b[39m\u001b[34m(self, text, **kwargs)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    629\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[32m    630\u001b[39m \n\u001b[32m    631\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    636\u001b[39m \u001b[33;03m        Embedding for the text.\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_openai/embeddings/base.py:590\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[32m    588\u001b[39m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[32m    589\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_openai/embeddings/base.py:478\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    482\u001b[39m         response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/openai/resources/embeddings.py:129\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    123\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    124\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m             ).tolist()\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "openai_embedding_large_64 = OpenAIEmbeddings(\n",
    "    model = \"text-embedding-3-large\", \n",
    "    # adding Dimension for the customization. \n",
    "    dimensions = 64\n",
    ")\n",
    "\n",
    "openap_embedding_small = OpenAIEmbeddings(\n",
    "    model = \"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "result  = openai_embedding_large_64.embed_query(\n",
    "    \"Nepal is a growing country.\"\n",
    ")\n",
    "\n",
    "result2 = openap_embedding_small.embed_query(\n",
    "    \"Nepal is a growing country.\"\n",
    ")\n",
    "\n",
    "print(len(result)) # got error because, api key is exceeded so need to purchase so. \n",
    "\n",
    "print(len(result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"what is a capital of USA\", \n",
    "             \"who is a present of USA\", \n",
    "             \"who is a prime minister of Nepal\"]\n",
    "\n",
    "result = openai_embedding.embed_documents(documents)\n",
    "\n",
    "print(len(result))\n",
    "\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[\"what is a capital of USA\",\n",
    "           \"who is a president of usa\",\n",
    "           \"who is a prime minister of india\"]\n",
    "\n",
    "my_query=\"narendra modi is indian prime minister\"\n",
    "\n",
    "query_embedding=openai_embedding.embed_query(my_query)\n",
    "document_embedding=openai_embedding.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fff2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "scores = cosine_similarity(\n",
    "    [query_embedding], \n",
    "    document_embedding\n",
    ")\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface Embedding. \n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "hugging_face_embeddings = HuggingFaceEmbeddings(\n",
    "        model_name = \"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Google Embedding. \n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "google_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model = \"models/embedding-001\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a24c57",
   "metadata": {},
   "source": [
    "### **Prompts Or Prompt_Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# My_model: \"GPT\"\n",
    "# System_Message: \"You are healthcare chatbot\"\n",
    "# Human_Message or User_Message: \"can you suggest me a best medicine for fever?\"\n",
    "# AI_Message or Model_Generated_Message: \"paracetamol/DOLO650 is a best medicine for fever.\"\n",
    "\n",
    "# Represent the overall behaviour of the model or context of the model. \n",
    "SystemMessage(\n",
    "    content = \"you are a funny bot means whatever you answer, you answer in the funny way\"\n",
    ")\n",
    "\n",
    "# Represent the user Message. \n",
    "HumanMessage(\n",
    "    content = \"who is your best friend\"\n",
    ")\n",
    "\n",
    "# \n",
    "message1 = [\n",
    "    SystemMessage(\n",
    "        content = \"you are a funny bot means whatever you answer, you answer in the funny way\"\n",
    "    ),\n",
    "\n",
    "    HumanMessage(\n",
    "        content = \"who is your best friend\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# \n",
    "message2 = [\n",
    "    SystemMessage(\n",
    "        content = \"you are a funny bot means whatever you answer, you answer in the funny way\"\n",
    "    ),\n",
    "\n",
    "    HumanMessage(\n",
    "        content = \"who is your best friend\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# \n",
    "result1 = openai_model.invoke(\n",
    "    message1\n",
    ").content\n",
    "\n",
    "result1\n",
    "\n",
    "result2 = openai_model.invoke(\n",
    "    message2\n",
    ").content\n",
    "\n",
    "result2\n",
    "\n",
    "message3 = [\n",
    "    SystemMessage(content=\"you are very helpful assistance you answer everything in detail\"),\n",
    "\n",
    "    HumanMessage(content=\"tell me the role of langchain in AI devlopment\")\n",
    "]\n",
    "\n",
    "result3 = message3.append(\n",
    "    AIMessage(openai_model.invoke(message3).content)\n",
    ")\n",
    "\n",
    "result3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168e95c",
   "metadata": {},
   "source": [
    "### **Create a ChatBot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "    SystemMessage(content = \"you are a helpful assistant\")\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"user_input: \")\n",
    "    chat_history.append(HumanMessage(content = user_input))\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "\n",
    "    result = openai_model.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(result.content))\n",
    "    print(\"AI Generated Answer: \", result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
