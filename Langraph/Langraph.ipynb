{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ad9f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langgraph) (0.3.65)\n",
      "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (43 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/user/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (1.3.1)\n",
      "Downloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
      "Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
      "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
      "Downloading ormsgpack-1.10.0-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (376 kB)\n",
      "Installing collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [langgraph]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langgraph-0.4.8 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 ormsgpack-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac267db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langgraph -> Orchestration(to create pipeline by combining a multiple components) -> pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa7fd8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: '<bound method Pregel.get_graph of <langgraph.graph.graph.CompiledGraph object at 0x124973390>>'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/IPython/core/display.py:1100\u001b[39m, in \u001b[36mImage._data_and_metadata\u001b[39m\u001b[34m(self, always_both)\u001b[39m\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1100\u001b[39m     b64_data = \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m.decode(\u001b[33m\"\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mTypeError\u001b[39m: a bytes-like object is required, not 'method'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/IPython/core/formatters.py:1036\u001b[39m, in \u001b[36mMimeBundleFormatter.__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m   1033\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/IPython/core/display.py:1090\u001b[39m, in \u001b[36mImage._repr_mimebundle_\u001b[39m\u001b[34m(self, include, exclude)\u001b[39m\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embed:\n\u001b[32m   1089\u001b[39m     mimetype = \u001b[38;5;28mself\u001b[39m._mimetype\n\u001b[32m-> \u001b[39m\u001b[32m1090\u001b[39m     data, metadata = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43malways_both\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1091\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[32m   1092\u001b[39m         metadata = {mimetype: metadata}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/IPython/core/display.py:1102\u001b[39m, in \u001b[36mImage._data_and_metadata\u001b[39m\u001b[34m(self, always_both)\u001b[39m\n\u001b[32m   1100\u001b[39m     b64_data = b2a_base64(\u001b[38;5;28mself\u001b[39m.data, newline=\u001b[38;5;28;01mFalse\u001b[39;00m).decode(\u001b[33m\"\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m   1103\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo such file or directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mself\u001b[39m.data)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1104\u001b[39m md = {}\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metadata:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No such file or directory: '<bound method Pregel.get_graph of <langgraph.graph.graph.CompiledGraph object at 0x124973390>>'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: '<bound method Pregel.get_graph of <langgraph.graph.graph.CompiledGraph object at 0x124973390>>'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/IPython/core/display.py:1100\u001b[39m, in \u001b[36mImage._data_and_metadata\u001b[39m\u001b[34m(self, always_both)\u001b[39m\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1100\u001b[39m     b64_data = \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m.decode(\u001b[33m\"\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mTypeError\u001b[39m: a bytes-like object is required, not 'method'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/IPython/core/formatters.py:406\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    404\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/IPython/core/display.py:1122\u001b[39m, in \u001b[36mImage._repr_png_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format == \u001b[38;5;28mself\u001b[39m._FMT_PNG:\n\u001b[32m-> \u001b[39m\u001b[32m1122\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/IPython/core/display.py:1102\u001b[39m, in \u001b[36mImage._data_and_metadata\u001b[39m\u001b[34m(self, always_both)\u001b[39m\n\u001b[32m   1100\u001b[39m     b64_data = b2a_base64(\u001b[38;5;28mself\u001b[39m.data, newline=\u001b[38;5;28;01mFalse\u001b[39;00m).decode(\u001b[33m\"\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m   1103\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo such file or directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mself\u001b[39m.data)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1104\u001b[39m md = {}\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metadata:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No such file or directory: '<bound method Pregel.get_graph of <langgraph.graph.graph.CompiledGraph object at 0x124973390>>'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Langgraph -> nodes, edges, state\n",
    "# node -> represent function. \n",
    "# edges -> represent connectivity between nodes (functions).\n",
    "# state\n",
    "from langgraph.graph import Graph\n",
    "from langgraph.graph import StateGraph\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from IPython.display import display, Image\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(\n",
    "#     model = \"models/embedding-001\"\n",
    "# )\n",
    "\n",
    "# llm = ChatGoogleGenerativeAI(\n",
    "#     model = \"gemini-1.5-pro\"\n",
    "# )\n",
    "\n",
    "def LLM(input):\n",
    "    llm = HuggingFaceEmbeddings(\n",
    "        model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(input).content\n",
    "\n",
    "    return response\n",
    "\n",
    "def Counter_Token(input):\n",
    "    token = input.split()\n",
    "    token_number = len(token)\n",
    "    response = f\"Total number of token in the generated output:  {token_number}\"\n",
    "    return response\n",
    "\n",
    "# creating a graph by initializing the Graph. \n",
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"My LLM\", LLM)\n",
    "workflow.add_node(\"Token Counter\", Counter_Token)\n",
    "workflow.add_edge(\"My LLM\", \"Token Counter\")\n",
    "\n",
    "workflow.set_entry_point(\"My LLM\")\n",
    "workflow.set_finish_point(\"Token Counter\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# Visualizing with the help of IPython display method. \n",
    "display(Image(app.get_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800f8a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/60/nyxyyg_s35nggs_b1klsdhm40000gn/T/ipykernel_44083/4272434875.py:22: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  llm = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for HuggingFaceEmbeddings\nmodel\n  Extra inputs are not permitted [type=extra_forbidden, input_value='sentence-transformers/all-MiniLM-L6-v2', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat is a agentic ai explain me in very detailed manner ?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mLLM\u001b[39m\u001b[34m(input)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mLLM\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     llm = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     response = llm.invoke(\u001b[38;5;28minput\u001b[39m).content\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:224\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    223\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/langchain_community/embeddings/huggingface.py:69\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any):\n\u001b[32m     68\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize the sentence_transformer.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m     72\u001b[39m         since = \u001b[33m\"\u001b[39m\u001b[33m0.2.16\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/genai_bootcamp/venv/lib/python3.13/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for HuggingFaceEmbeddings\nmodel\n  Extra inputs are not permitted [type=extra_forbidden, input_value='sentence-transformers/all-MiniLM-L6-v2', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden",
      "During task with name 'My LLM' and id '12933f78-5e15-45e4-0e9c-91631906f960'"
     ]
    }
   ],
   "source": [
    "# \n",
    "app.invoke(\"what is a agentic ai explain me in very detailed manner ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465376b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"what is a agentic ai explain me in very detailed manner ?\"\n",
    "# Checking the output of the each node. \n",
    "for output in app.stream(input):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Here is output from {key}\")\n",
    "        print(\"_______\")\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0754f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c259f3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac0f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "739d6c8d",
   "metadata": {},
   "source": [
    "#### **state graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "485a84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd07e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\n",
    "    \"../data\",\n",
    "    glob = \"./*.txt\",\n",
    "    loader_cls = TextLoader\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500, \n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "doc_strings\n",
    "\n",
    "# storing the data in vector db. \n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs = {\"k\": 3})\n",
    "\n",
    "# \n",
    "\n",
    "query  = \"why scientist was working hard for what kind of vaccines ?\"\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "print(docs[0].metadaata)\n",
    "print(docs[0].page_content)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f68d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We are flowing this state across the different nodes inside the langraph workflow. \n",
    "AgentState = {}\n",
    "\n",
    "AgentState[\"messages\"] = []\n",
    "\n",
    "def function1(AgentState):\n",
    "    message = AgentState[\"messages\"]\n",
    "\n",
    "    question = message[-1]\n",
    "\n",
    "    complete_prompt = \"You task is to provide only the brief answer based on the user query. \\ Don't include too much reasoning. Following is the user query: \" + question\n",
    "\n",
    "    response = llm.invoke(complete_prompt)\n",
    "\n",
    "    AgentState[\"messages\"].append(response.content) # appending LLM call response to the AgentState. \n",
    "\n",
    "    return AgentState\n",
    "\n",
    "# This below is the RAG pipeline. \n",
    "def function2(AgentState): \n",
    "\n",
    "    messages = AgentState[\"messages\"]\n",
    "\n",
    "    question = messages[0] ## Fetching the user question.\n",
    "\n",
    "    template = \"\"\"Answer the question based only on the following context: \n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    retrieval_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt \n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    result = retrieval_chain.invoke(question)\n",
    "    return result\n",
    "\n",
    "# This is the Orchestration -> Creating a Pipeline. \n",
    "workflow = Graph()\n",
    "workflow.add_node(\"LLM\", function1)\n",
    "workflow.add_node('RAGtool', function2)\n",
    "workflow.add_edge(\"LLM\", \"RAGtool\")\n",
    "workflow.set_entry_point(\"LLM\")\n",
    "workflow.set_finish_point(\"RAGtool\")\n",
    "app2 = workflow.compile()\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7aea887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay I am good\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "app2.invoke({\"messages\": [\"hi\", \"how are you doing ?\", \"Okay I am good\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"what is a meaning of cancer from prolonged exposure to burn pits raveged health lung?\"\n",
    "# Checking the output of the each node. \n",
    "for output in app.stream({\"messages\": [\"what is a meaning of cancer from prolonged exposure to burn pits raveged health lung?\"]}):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Here is output from {key}\")\n",
    "        print(\"_______\")\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cae155ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentState[\"messages\"].append(\"Hi\")\n",
    "\n",
    "AgentState[\"messages\"].append(\"Hello\")\n",
    "\n",
    "AgentState[\"messages\"].append(\"we need to study mL. \")\n",
    "\n",
    "AgentState[\"messages\"].append(\"Okay FIne...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "969fff5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d87371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
